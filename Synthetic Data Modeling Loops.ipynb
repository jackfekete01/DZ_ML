{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a00475-276e-4f90-96c9-3ac86df2e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all packages \n",
    "import pickle\n",
    "import detritalpy.detritalFuncs as dFunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "import random\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43e03c0-984c-439d-89fd-d5a49f05cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_que = {}\n",
    "\n",
    "data_que['0.15-0.25'] = [['0.15-0.25 - 0 Sources.p','0.15-0.25 - 1 Sources.p','0.15-0.25 - 2 Sources.p','0.15-0.25 - 3 Sources.p',\n",
    "                          '0.15-0.25 - 4 Sources.p','0.15-0.25 - 5 Sources.p','0.15-0.25 - 6 Sources.p','0.15-0.25 - 7 Sources.p'],\n",
    "                         'New 0.15-0.25 Sources.p']\n",
    "\n",
    "data_que['0.25-0.35'] = [['0.25-0.35 - 0 Sources.p','0.25-0.35 - 1 Sources.p','0.25-0.35 - 2 Sources.p','0.25-0.35 - 3 Sources.p',\n",
    "                          '0.25-0.35 - 4 Sources.p','0.25-0.35 - 5 Sources.p','0.25-0.35 - 6 Sources.p','0.25-0.35 - 7 Sources.p'],\n",
    "                         'New 0.25-0.35 Sources.p']\n",
    "\n",
    "data_que['0.35-0.45'] = [['0.35-0.45 - 0 Sources.p','0.35-0.45 - 1 Sources.p','0.35-0.45 - 2 Sources.p','0.35-0.45 - 3 Sources.p',\n",
    "                          '0.35-0.45 - 4 Sources.p','0.35-0.45 - 5 Sources.p','0.35-0.45 - 6 Sources.p','0.35-0.45 - 7 Sources.p'],\n",
    "                         'New 0.35-0.45 Sources.p']\n",
    "\n",
    "data_que['0.45-0.55'] = [['0.45-0.55 - 0 Sources.p','0.45-0.55 - 1 Sources.p','0.45-0.55 - 2 Sources.p','0.45-0.55 - 3 Sources.p',\n",
    "                          '0.45-0.55 - 4 Sources.p','0.45-0.55 - 5 Sources.p','0.45-0.55 - 6 Sources.p','0.45-0.55 - 7 Sources.p'],\n",
    "                         'New 0.45-0.55 Sources.p']\n",
    "\n",
    "data_que['0.55-0.65'] = [['0.55-0.65 - 0 Sources.p','0.55-0.65 - 1 Sources.p','0.55-0.65 - 2 Sources.p','0.55-0.65 - 3 Sources.p',\n",
    "                          '0.55-0.65 - 4 Sources.p','0.55-0.65 - 5 Sources.p','0.55-0.65 - 6 Sources.p','0.55-0.65 - 7 Sources.p'],\n",
    "                         'New 0.55-0.65 Sources.p']\n",
    "\n",
    "data_que['0.65-0.75'] = [['0.65-0.75 - 0 Sources.p','0.65-0.75 - 1 Sources.p','0.65-0.75 - 2 Sources.p','0.65-0.75 - 3 Sources.p',\n",
    "                          '0.65-0.75 - 4 Sources.p','0.65-0.75 - 5 Sources.p','0.65-0.75 - 6 Sources.p','0.65-0.75 - 7 Sources.p'],\n",
    "                         'New 0.65-0.75 Sources.p']\n",
    "\n",
    "data_que['0.75-0.85'] = [['0.75-0.85 - 0 Sources.p','0.75-0.85 - 1 Sources.p','0.75-0.85 - 2 Sources.p','0.75-0.85 - 3 Sources.p',\n",
    "                          '0.75-0.85 - 4 Sources.p','0.75-0.85 - 5 Sources.p','0.75-0.85 - 6 Sources.p','0.75-0.85 - 7 Sources.p'],\n",
    "                         'New 0.75-0.85 Sources.p']\n",
    "\n",
    "data_que['0.85-0.95'] = [['0.85-0.95 - 0 Sources.p','0.85-0.95 - 1 Sources.p','0.85-0.95 - 2 Sources.p','0.85-0.95 - 3 Sources.p',\n",
    "                          '0.85-0.95 - 4 Sources.p','0.85-0.95 - 5 Sources.p','0.85-0.95 - 6 Sources.p','0.85-0.95 - 7 Sources.p'],\n",
    "                         'New 0.85-0.95 Sources.p']\n",
    "\n",
    "                          \n",
    "data_que['0.95-0.99'] = [['0.95-0.99 - 0 Sources.p','0.95-0.99 - 1 Sources.p','0.95-0.99 - 2 Sources.p','0.95-0.99 - 3 Sources.p',\n",
    "                          '0.95-0.99 - 4 Sources.p','0.95-0.99 - 5 Sources.p','0.95-0.99 - 6 Sources.p','0.95-0.99 - 7 Sources.p'],\n",
    "                         'New 0.95-0.99 Sources.p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61050f95-00ce-4328-b818-1b2c7c852f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUTS\n",
    "################################################################################################\n",
    "\n",
    "# Number of times the ML pipeline will be trained and tested on the selected data\n",
    "num_repeats = 10\n",
    "# Place the TPOT pipeline from your code or example below:\n",
    "TPOT_pipeline = MultinomialNB(alpha=0.001, fit_prior=False)\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "# Set up the loop\n",
    "hit_vals = np.round(np.logspace(1,3,num=35),0)\n",
    "# Load in data for each similarity interval\n",
    "for data_pair in data_que:\n",
    "    source_data = data_que[data_pair][0]\n",
    "    init_data = {}\n",
    "    for source in source_data:\n",
    "        load_data = pickle.load(open(source,'rb'))\n",
    "        init_data.update(load_data)\n",
    "    OG_sources = pickle.load(open(data_que[data_pair][1],'rb'))\n",
    "\n",
    "    # Initial final storage for data pair\n",
    "    results_total = {}\n",
    "    R2_totals = {}\n",
    "    RF_totals = {}\n",
    "    #######################################################################################\n",
    "    # Setting up loops and selecting keys\n",
    "    # w is for grains\n",
    "    for w in hit_vals:\n",
    "        round_start = time.time()\n",
    "        # t is for sources\n",
    "        for t in range(2,9):\n",
    "            # AutoML storage\n",
    "            ###################\n",
    "            f1_bank = []\n",
    "            acc_bank = []\n",
    "            prec_bank = []\n",
    "            recall_bank = []\n",
    "            sim_bank = []\n",
    "            # R2 Storage\n",
    "            ###################\n",
    "            R2_F1_bank = []\n",
    "            R2_acc_bank = []\n",
    "            R2_prec_bank = []\n",
    "            R2_recall_bank = []\n",
    "            # Random Forest Storage\n",
    "            ####################\n",
    "            RF_F1_bank = []\n",
    "            RF_acc_bank = []\n",
    "            RF_prec_bank = []\n",
    "            RF_recall_bank = []\n",
    "            ####################\n",
    "            # Start loops\n",
    "            start = time.time()\n",
    "            for v in range(0,num_repeats):\n",
    "                # temp spot to hold the data\n",
    "                data_hold = {}\n",
    "                # Randomly select keys to compare\n",
    "                select_keys = random.sample(range(0,8),t)\n",
    "                for key in init_data:\n",
    "                    if key[1] == w and key[0] in select_keys:\n",
    "                        data_hold[key] = init_data[key]\n",
    "                # Now we need to go through and separate the data and assign labels\n",
    "        ########################################################################################\n",
    "                # Data structuring\n",
    "                ID_list = []\n",
    "                KDE_list = []\n",
    "                for entry in data_hold:\n",
    "                    source_ID = entry[0]\n",
    "                    for KDE in data_hold[entry]:\n",
    "                        KDE_list.append(KDE)\n",
    "                        ID_list.append(source_ID)\n",
    "                final_df = pd.DataFrame()\n",
    "                final_df['ID'] = ID_list\n",
    "                final_df['KDE'] = KDE_list\n",
    "        ########################################################################################\n",
    "\n",
    "        #########################################################################################\n",
    "                # All the ML stuff ###############################\n",
    "                train_set,test_set = train_test_split(final_df,test_size = 0.2, random_state = randrange(42))\n",
    "                train_KDE = list(train_set['KDE'])\n",
    "                train_labels = list(train_set['ID'])\n",
    "                test_KDE = list(test_set['KDE'])\n",
    "                test_labels = list(test_set['ID'])\n",
    "                enc = OrdinalEncoder()\n",
    "                train_labels = np.array(train_labels)\n",
    "                train_labels = train_labels.reshape(-1,1)\n",
    "                train_labels = enc.fit_transform(train_labels)\n",
    "                test_labels = np.array(test_labels)\n",
    "                test_labels = test_labels.reshape(-1,1)\n",
    "                test_labels = enc.fit_transform(test_labels)\n",
    "                exported_pipeline = TPOT_pipeline\n",
    "                # Fix random state in exported estimator\n",
    "                if hasattr(exported_pipeline, 'random_state'):\n",
    "                    setattr(exported_pipeline, 'random_state', 42)\n",
    "                model = exported_pipeline.fit(train_KDE,train_labels.ravel())\n",
    "                results = exported_pipeline.predict(test_KDE)\n",
    "\n",
    "        ######### GET THE SCORES #################################################################\n",
    "                F1 = f1_score(test_labels,results,average='weighted')\n",
    "                acc = accuracy_score(test_labels,results)\n",
    "                prec = precision_score(test_labels,results,average='weighted',zero_division = 0)\n",
    "                rec = recall_score(test_labels,results,average='weighted',zero_division = 0)\n",
    "                #final_sim_score = (sum(total_sim_scores)/len(total_sim_scores))\n",
    "                f1_bank.append(F1)\n",
    "                acc_bank.append(acc)\n",
    "                prec_bank.append(prec)\n",
    "                recall_bank.append(rec)\n",
    "                #sim_bank.append(final_sim_score)\n",
    "\n",
    "        ####### Random Forest Tests ############################################################\n",
    "                RF_start = time.time()\n",
    "                rf_clf = RandomForestClassifier()\n",
    "                rf_model = rf_clf.fit(train_KDE,train_labels.ravel())\n",
    "                rf_results = rf_clf.predict(test_KDE)\n",
    "\n",
    "                # Get scores\n",
    "                rf_f1 = f1_score(test_labels,rf_results,average='weighted')\n",
    "                rf_acc = accuracy_score(test_labels,rf_results)\n",
    "                rf_prec = precision_score(test_labels,rf_results,average='weighted',zero_division = 0)\n",
    "                rf_rec = recall_score(test_labels,rf_results,average='weighted',zero_division = 0)\n",
    "                #final_sim_score = (sum(total_sim_scores)/len(total_sim_scores))\n",
    "                RF_F1_bank.append(rf_f1)\n",
    "                RF_acc_bank.append(rf_acc)\n",
    "                RF_prec_bank.append(rf_prec)\n",
    "                RF_recall_bank.append(rf_rec)\n",
    "                #sim_bank.append(final_sim_score)\n",
    "\n",
    "        ######## GET R2 Scores ###################################################################\n",
    "                R2_start = time.time()\n",
    "                R2_preds = []\n",
    "                R2_labels = []\n",
    "                used_sources = {}\n",
    "                for key in select_keys:\n",
    "                    used_sources[key] = OG_sources[key]\n",
    "                for index in test_set.index:\n",
    "                    temp_dict = {}\n",
    "                    test_KDE = test_set.loc[index]['KDE']\n",
    "                    test_ID = test_set.loc[index]['ID']\n",
    "                    R2_labels.append(test_ID)\n",
    "                    for source in used_sources:\n",
    "                        OG_source = OG_sources[source][0]\n",
    "                        R2_score = dFunc.calcR2(test_KDE,OG_source)\n",
    "                        temp_dict[source] = R2_score\n",
    "                    max_val = max(temp_dict, key = temp_dict.get)\n",
    "                    R2_preds.append(max_val)\n",
    "                # Now we get the scores\n",
    "                R2_F1 = f1_score(R2_labels,R2_preds,average='weighted')\n",
    "                R2_acc = accuracy_score(R2_labels,R2_preds)\n",
    "                R2_prec = precision_score(R2_labels,R2_preds,average='weighted',zero_division = 0)\n",
    "                R2_rec = recall_score(R2_labels,R2_preds,average='weighted',zero_division = 0)\n",
    "                R2_F1_bank.append(R2_F1)\n",
    "                R2_acc_bank.append(R2_acc)\n",
    "                R2_prec_bank.append(R2_prec)\n",
    "                R2_recall_bank.append(R2_rec)\n",
    "                \n",
    "        ##########################################################################################\n",
    "            end = time.time()\n",
    "            total_elapsed_time = end-start   \n",
    "            f1_final = sum(f1_bank)/len(f1_bank)\n",
    "            print()\n",
    "            print('AutoML - F1 Score:',round(f1_final,2))\n",
    "            #sim_final = sum(sim_bank)/len(sim_bank)\n",
    "            sim_final = None\n",
    "            acc_final = sum(acc_bank)/len(acc_bank)\n",
    "            prec_final =  sum(prec_bank)/len(prec_bank)\n",
    "            recall_final = sum(recall_bank)/len(recall_bank)\n",
    "            results_total[(t),w] = [f1_final,sim_final,acc_final,prec_final,recall_final,total_elapsed_time,f1_bank]\n",
    "            #print('Finished ML',w,t)\n",
    "    ##########################################################################################\n",
    "            R2_end = time.time()\n",
    "            final_sim_score = None\n",
    "            R2_time = R2_end - R2_start\n",
    "            R2_F1_final = sum(R2_F1_bank)/len(R2_F1_bank)\n",
    "            print('R2 - F1 Score:',round(R2_F1_final,2))\n",
    "            R2_acc_final = sum(R2_acc_bank)/len(R2_acc_bank)\n",
    "            R2_prec_final = sum(R2_prec_bank)/len(R2_prec_bank)\n",
    "            R2_recall_final = sum(R2_recall_bank)/len(R2_recall_bank)\n",
    "            R2_totals[(t),w] = [R2_F1_final,final_sim_score,R2_acc_final,R2_prec_final,R2_recall_final,R2_time]\n",
    "    ############################################################################################\n",
    "            RF_end = time.time()\n",
    "            final_sim_score = None\n",
    "            RF_time = RF_end-RF_start\n",
    "            RF_F1_final = sum(RF_F1_bank)/len(RF_F1_bank)\n",
    "            print('Random Forest - F1 Score:',round(RF_F1_final,2))\n",
    "            RF_acc_final = sum(RF_acc_bank)/len(RF_acc_bank)\n",
    "            RF_prec_final = sum(RF_prec_bank)/len(RF_prec_bank)\n",
    "            RF_recall_final = sum(RF_recall_bank)/len(RF_recall_bank)\n",
    "            RF_totals[(t),w] = [RF_F1_final,final_sim_score,RF_acc_final,RF_prec_final,RF_recall_final,RF_time]\n",
    "\n",
    "        round_end = time.time()\n",
    "        print()\n",
    "        print('Round Training Time:',round((round_end-round_start),2),' seconds.')\n",
    "        print('Finished with Analyses:',w)\n",
    "    ML_naming_id = 'Fixed '+data_pair+' AutoML Results.p'\n",
    "    R2_naming_id = 'Fixed '+data_pair+' R2 Results.p'\n",
    "    RF_naming_id = 'Fixed '+data_pair+' RF Results.p'\n",
    "    pickle.dump(results_total,open(ML_naming_id,'wb'))\n",
    "    pickle.dump(R2_totals,open(R2_naming_id,'wb'))\n",
    "    pickle.dump(RF_totals,open(RF_naming_id,'wb'))\n",
    "    print('Succesful save.')\n",
    "    print('Deleting old data.')\n",
    "    print()\n",
    "    print('----------------------')\n",
    "    del init_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894a76d-4d26-4f90-a461-06266ac78ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
